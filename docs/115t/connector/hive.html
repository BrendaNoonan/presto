
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>8.2. Hive Connector &mdash; Presto 0.115t Documentation</title>
    
    <link rel="stylesheet" href="../_static/presto.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.115t',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="Presto 0.115t Documentation" href="../index.html" />
    <link rel="up" title="8. Connectors" href="../connector.html" />
    <link rel="next" title="8.3. JMX Connector" href="jmx.html" />
    <link rel="prev" title="8.1. Black Hole Connector" href="blackhole.html" /> 
  </head>
  <body>
<div class="header">
    <h1 class="heading"><a href="../index.html">
        <span>Presto 0.115t Documentation</span></a></h1>
    <h2 class="heading"><span>8.2. Hive Connector</span></h2>
</div>
<div class="topnav">
    
<p class="nav">
    <span class="left">
        &laquo; <a href="blackhole.html">8.1. Black Hole Connector</a>
    </span>
    <span class="right">
        <a href="jmx.html">8.3. JMX Connector</a> &raquo;
    </span>
</p>

</div>
<div class="content">
    
  <div class="section" id="hive-connector">
<h1>8.2. Hive Connector</h1>
<p>The Hive connector allows querying data stored in a Hive
data warehouse. Hive is a combination of three components:</p>
<ul class="simple">
<li>Data files in varying formats that are typically stored in the
Hadoop Distributed File System (HDFS) or in Amazon S3.</li>
<li>Metadata about how the data files are mapped to schemas and tables.
This metadata is stored in a database such as MySQL and is accessed
via the Hive metastore service.</li>
<li>A query language called HiveQL. This query language is executed
on a distributed computing framework such as MapReduce or Tez.</li>
</ul>
<p>Presto only uses the first two components: the data and the metadata.
It does not use HiveQL or any part of Hive&#8217;s execution environment.</p>
<div class="section" id="supported-file-types">
<h2>Supported File Types</h2>
<p>The following file types are supported for the Hive connector:</p>
<ul class="simple">
<li>ORC</li>
<li>RCFile</li>
<li>TEXT</li>
<li>Parquet</li>
</ul>
</div>
<div class="section" id="configuration">
<h2>Configuration</h2>
<p>Presto includes Hive connectors for multiple versions of Hadoop:</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">hive-hadoop2</span></tt>: Apache Hadoop 2.x</li>
<li><tt class="docutils literal"><span class="pre">hive-cdh5</span></tt>: Cloudera CDH 5</li>
</ul>
<p>Create <tt class="docutils literal"><span class="pre">/etc/presto/catalog/hive.properties</span></tt> with the following contents
to mount the <tt class="docutils literal"><span class="pre">hive-hadoop2</span></tt> connector as the <tt class="docutils literal"><span class="pre">hive</span></tt> catalog,
replacing <tt class="docutils literal"><span class="pre">hive-hadoop2</span></tt> with the proper connector for your version
of Hadoop and <tt class="docutils literal"><span class="pre">example.net:9083</span></tt> with the correct host and port
for your Hive metastore Thrift service:</p>
<div class="highlight-none"><div class="highlight"><pre>connector.name=hive-hadoop2
hive.metastore.uri=thrift://example.net:9083
</pre></div>
</div>
<p>Additionally, you should add the following property to <tt class="docutils literal"><span class="pre">jvm.config</span></tt>, replacing &lt;hdfs_username&gt; with your hdfs user name:</p>
<div class="highlight-sql"><div class="highlight"><pre><span class="o">-</span><span class="n">DHADOOP_USER_NAME</span><span class="o">=&lt;</span><span class="n">hdfs_username</span><span class="o">&gt;</span>
</pre></div>
</div>
<div class="section" id="multiple-hive-clusters">
<h3>Multiple Hive Clusters</h3>
<p>You can have as many catalogs as you need, so if you have additional
Hive clusters, simply add another properties file to <tt class="docutils literal"><span class="pre">/etc/presto/catalog</span></tt>
with a different name (making sure it ends in <tt class="docutils literal"><span class="pre">.properties</span></tt>). For
example, if you name the property file <tt class="docutils literal"><span class="pre">sales.properties</span></tt>, Presto
will create a catalog named <tt class="docutils literal"><span class="pre">sales</span></tt> using the configured connector.
If you are connecting to more than one Hive metastore, you can create
any number of properties files configuring multiple instances of
the Hive connector.</p>
</div>
<div class="section" id="hdfs-configuration">
<h3>HDFS Configuration</h3>
<p>Presto configures the HDFS client automatically for most setups and
does not require any configuration files. In some rare cases, such
as when using federated HDFS or high availability Hive, it may be necessary to specify additional
HDFS client options in order to access your HDFS cluster. To do so, add
the <tt class="docutils literal"><span class="pre">hive.config.resources</span></tt> property to reference your HDFS config files:</p>
<div class="highlight-none"><div class="highlight"><pre>hive.config.resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml
</pre></div>
</div>
<p>Only specify additional configuration files if absolutely necessary.
We also recommend reducing the configuration files to have the minimum
set of required properties, as additional properties may cause problems.</p>
</div>
<div class="section" id="hdfs-permissions">
<h3>HDFS Permissions</h3>
<p>Before running any <tt class="docutils literal"><span class="pre">CREATE</span> <span class="pre">TABLE</span></tt> or <tt class="docutils literal"><span class="pre">CREATE</span> <span class="pre">TABLE</span> <span class="pre">...</span> <span class="pre">AS</span></tt> statements
for Hive tables in Presto, you need to check that the operating system user
running the Presto server has access to the Hive warehouse directory on HDFS. The Hive warehouse
directory is specified by the configuration variable <tt class="docutils literal"><span class="pre">hive.metastore.warehouse.dir</span></tt>
in <tt class="docutils literal"><span class="pre">hive-site.xml</span></tt>, and the default value is <tt class="docutils literal"><span class="pre">/user/hive/warehouse</span></tt>. If that
is not the case, either add the following to <tt class="docutils literal"><span class="pre">jvm.config</span></tt> on all of the nodes:
<tt class="docutils literal"><span class="pre">-DHADOOP_USER_NAME=USER</span></tt>, where <tt class="docutils literal"><span class="pre">USER</span></tt> is an operating system user that has proper
permissions for the Hive warehouse directory, or start the Presto server as a user with
similar permissions. The <tt class="docutils literal"><span class="pre">hive</span></tt> user generally works as <tt class="docutils literal"><span class="pre">USER</span></tt>, since Hive is often
started with the <tt class="docutils literal"><span class="pre">hive</span></tt> user. If you run into HDFS permissions problems on
<tt class="docutils literal"><span class="pre">CREATE</span> <span class="pre">TABLE</span> <span class="pre">...</span> <span class="pre">AS</span></tt>, remove <tt class="docutils literal"><span class="pre">/tmp/presto-*</span></tt> on HDFS, fix the user as described
above, then restart all of the Presto servers.</p>
</div>
</div>
<div class="section" id="configuration-properties">
<h2>Configuration Properties</h2>
<table border="1" class="docutils">
<colgroup>
<col width="41%" />
<col width="49%" />
<col width="10%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Property Name</th>
<th class="head">Description</th>
<th class="head">Default</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><tt class="docutils literal"><span class="pre">hive.metastore.uri</span></tt></td>
<td>The URI(s) of the Hive Metastore to connect to using
the Thrift protocol. If a comma-separated list of URIs is
provided, the first URI is used by default, and the rest of
the URIs are fallback Metastores. This property is required.
Example: <tt class="docutils literal"><span class="pre">thrift://192.0.2.3:9083</span></tt> or
<tt class="docutils literal"><span class="pre">thrift://192.0.2.3:9083,thrift://192.0.2.4:9083</span></tt></td>
<td>&nbsp;</td>
</tr>
<tr class="row-odd"><td><tt class="docutils literal"><span class="pre">hive.config.resources</span></tt></td>
<td>An optional comma-separated list of HDFS
configuration files. These files must exist on the
machines running Presto. Only specify this if
absolutely necessary to access HDFS.
Example: <tt class="docutils literal"><span class="pre">/etc/hdfs-site.xml</span></tt></td>
<td>&nbsp;</td>
</tr>
<tr class="row-even"><td><tt class="docutils literal"><span class="pre">hive.storage-format</span></tt></td>
<td>The default file format used when creating new tables.</td>
<td><tt class="docutils literal"><span class="pre">RCBINARY</span></tt></td>
</tr>
<tr class="row-odd"><td><tt class="docutils literal"><span class="pre">hive.force-local-scheduling</span></tt></td>
<td>Force splits to be scheduled on the same node as the Hadoop
DataNode process serving the split data.  This is useful for
installations where Presto is collocated with every
DataNode.</td>
<td><tt class="docutils literal"><span class="pre">false</span></tt></td>
</tr>
<tr class="row-even"><td><tt class="docutils literal"><span class="pre">hive.allow-drop-table</span></tt></td>
<td>Allow the Hive connector to drop tables.</td>
<td><tt class="docutils literal"><span class="pre">false</span></tt></td>
</tr>
<tr class="row-odd"><td><tt class="docutils literal"><span class="pre">hive.allow-rename-table</span></tt></td>
<td>Allow the Hive connector to rename tables.</td>
<td><tt class="docutils literal"><span class="pre">false</span></tt></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="querying-hive-tables">
<h2>Querying Hive Tables</h2>
<p>The following table is an example Hive table from the <a class="reference external" href="https://cwiki.apache.org/confluence/display/Hive/Tutorial#Tutorial-UsageandExamples">Hive Tutorial</a>.
It can be created in Hive (not in Presto) using the following
Hive <tt class="docutils literal"><span class="pre">CREATE</span> <span class="pre">TABLE</span></tt> command:</p>
<div class="highlight-none"><div class="highlight"><pre>hive&gt; CREATE TABLE page_view (
    &gt;   viewTime INT,
    &gt;   userid BIGINT,
    &gt;   page_url STRING,
    &gt;   referrer_url STRING,
    &gt;   ip STRING COMMENT &#39;IP Address of the User&#39;)
    &gt; COMMENT &#39;This is the page view table&#39;
    &gt; PARTITIONED BY (dt STRING, country STRING)
    &gt; STORED AS SEQUENCEFILE;
OK
Time taken: 3.644 seconds
</pre></div>
</div>
<p>Assuming that this table was created in the <tt class="docutils literal"><span class="pre">web</span></tt> schema in
Hive, this table can be described in Presto:</p>
<div class="highlight-sql"><div class="highlight"><pre><span class="k">DESCRIBE</span> <span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="n">page_view</span><span class="p">;</span>
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>    Column    |  Type   | Null | Partition Key |        Comment
--------------+---------+------+---------------+------------------------
 viewtime     | bigint  | true | false         |
 userid       | bigint  | true | false         |
 page_url     | varchar | true | false         |
 referrer_url | varchar | true | false         |
 ip           | varchar | true | false         | IP Address of the User
 dt           | varchar | true | true          |
 country      | varchar | true | true          |
(7 rows)
</pre></div>
</div>
<p>This table can then be queried in Presto:</p>
<div class="highlight-sql"><div class="highlight"><pre><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="n">page_view</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="section" id="custom-storage-handlers">
<h2>Custom Storage Handlers</h2>
<p>Hive tables can use custom storage handlers to support alternative data formats.
To query from Hive tables that use custom storage handlers, you will need the
JARs containing the storage handler classes.  Copy the storage handler JARs to
the connector plugin directory on all nodes, restart the presto servers, and
then query the table as you would any other Hive table.  You can copy the
jar across the cluster using presto-admin&#8217;s <tt class="docutils literal"><span class="pre">plugin</span> <span class="pre">add_jar</span></tt> command and
restart servers by using the <tt class="docutils literal"><span class="pre">server</span> <span class="pre">restart</span></tt> command.</p>
<p>For example, if the plugin directory is located at
<tt class="docutils literal"><span class="pre">/usr/lib/presto/lib/plugin</span></tt>, and you want to use the <tt class="docutils literal"><span class="pre">hive-hadoop2</span></tt>
connector to query from a table that uses a storage handler available
in <tt class="docutils literal"><span class="pre">/tmp/my-classes.jar</span></tt>:</p>
<ol class="arabic">
<li><p class="first">Copy <tt class="docutils literal"><span class="pre">my-classes.jar</span></tt> into <tt class="docutils literal"><span class="pre">/usr/lib/presto/lib/plugin/hive-hadoop2</span></tt>
on all nodes of the cluster.</p>
<div class="highlight-sql"><div class="highlight"><pre><span class="n">sudo</span> <span class="p">.</span><span class="o">/</span><span class="n">presto</span><span class="o">-</span><span class="k">admin</span> <span class="n">plugin</span> <span class="n">add_jar</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">my</span><span class="o">-</span><span class="n">classes</span><span class="p">.</span><span class="n">jar</span> <span class="n">hive</span><span class="o">-</span><span class="n">hadoop2</span>
</pre></div>
</div>
</li>
<li><p class="first">Restart your presto-servers:</p>
<div class="highlight-sql"><div class="highlight"><pre><span class="n">sudo</span> <span class="p">.</span><span class="o">/</span><span class="n">presto</span><span class="o">-</span><span class="k">admin</span> <span class="n">server</span> <span class="k">restart</span>
</pre></div>
</div>
</li>
</ol>
<p>Then you can query from the table as you would any other Hive table in Presto.</p>
</div>
</div>


</div>
<div class="bottomnav">
    
<p class="nav">
    <span class="left">
        &laquo; <a href="blackhole.html">8.1. Black Hole Connector</a>
    </span>
    <span class="right">
        <a href="jmx.html">8.3. JMX Connector</a> &raquo;
    </span>
</p>

</div>

    <div class="footer">
    </div>
  </body>
</html>